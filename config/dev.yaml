app:
  env: "dev"
  log_level: "INFO"

ingestion:
  delimiter: "Ã‡"
  fallback_encodings: ["utf-8", "latin-1"]
  skip_bad_lines: true
  max_rows_preview: 5000

rag:
  backend: "chroma"
  s3vectors:
    bucket: ""
    index: ""
    namespace: "default"
    refresh_seconds: 300
  s3_vector:
    bucket: ""
    prefix: "nl-analytics/vectors"
    cache_dir: ".s3_vector_cache"
    refresh_seconds: 300
  chroma_dir: ".chroma"
  top_k: 8
  min_score: 0.25
  chunk_size: 900
  chunk_overlap: 80

agent:
  min_confidence: 0.45
  refuse_below_confidence: true

models:
  provider: "bedrock"
  region: "us-east-1"
  chat_model_id: "anthropic.claude-3-haiku-20240307-v1:0"
  embed_model_id: "amazon.titan-embed-text-v1"
  temperature: 0.1
  max_tokens: 1200

export:
  export_dir: "data/exports"
  saved_query_dir: "data/saved_queries"

# ---------------------------------------------------------------------------
# Query execution backend:
#   - duckdb   : local in-memory SQL over workspace dataframes (current default)
#   - athena   : run SQL in Athena against Glue/S3 tables
#   - redshift : run SQL using Redshift Data API
#
# You can override any value below using environment variables:
#   DB_TYPE=athena|redshift|duckdb
#   ATHENA_DATABASE, ATHENA_OUTPUT_LOCATION, ATHENA_WORKGROUP
#   REDSHIFT_DATABASE, REDSHIFT_CLUSTER_ID or REDSHIFT_WORKGROUP_NAME,
#   REDSHIFT_DB_USER or REDSHIFT_SECRET_ARN
# ---------------------------------------------------------------------------
database:
  db_type: "duckdb"
  athena:
    database: ""
    workgroup: ""
    output_location: ""   # e.g., s3://my-bucket/athena-results/
    catalog: "AwsDataCatalog"
  redshift:
    database: ""
    cluster_id: ""        # for provisioned Redshift
    workgroup_name: ""    # for Redshift Serverless
    db_user: ""           # optional if using secret_arn
    secret_arn: ""        # preferred for auth
